---
title: "Elegir Modelo de IA"
description: "Seleccione y configure el modelo de lenguaje que impulsa el razonamiento de su agente"
icon: "brain"
"keywords": "selección de modelo de IA, modelos de lenguaje, GPT-4, Claude, selección de LLM, inteligencia artificial, configuración de modelo, cerebro del agente"
"og:description": "Seleccione y configure el modelo de lenguaje que impulsa el razonamiento de su agente de IA, desde GPT-4 hasta Claude y más."
---

## Descripción General

El modelo de IA (LLM) es el cerebro de su agente de voz. Procesa lo que dicen los clientes, comprende su intención, razona sobre la mejor respuesta y decide cuándo tomar acciones. Elegir el modelo correcto significa equilibrar el rendimiento, la latencia, el costo y los requisitos de cumplimiento.

<Note>
La selección de modelo ocurre en **Modelos > Modelo** en la configuración de su agente. Los cambios se aplican inmediatamente—no se requiere un paso de publicación separado.
</Note>

## Comprender los Modelos de Lenguaje

Los modelos de lenguaje se entrenan con grandes cantidades de texto para comprender y generar lenguaje humano. En los agentes de voz, el LLM interpreta las solicitudes de los clientes, razona sobre la mejor respuesta según sus instrucciones y base de conocimiento, decide cuándo usar acciones como transferencias o reservas, genera respuestas de conversación naturales y mantiene el contexto a lo largo de la conversación.

Los diferentes modelos destacan en diferentes tareas. Algunos priorizan la velocidad, otros la precisión, y algunos ofrecen el mejor equilibrio para la IA conversacional.

---

## Modelos Recomendados

Basados en el rendimiento en el mundo real de miles de agentes de voz, estos son los modelos probados para diferentes casos de uso:

<AccordionGroup>
  <Accordion title="Mejor para la Mayoría de Casos de Uso: GPT-4.1 Mini" icon="star" defaultOpen>
    **Nuestra principal recomendación** para agentes de voz en producción.

    **Por qué funciona:**
    - Excelente latencia (~700-800ms tiempo de respuesta)
    - 70%+ tasa de éxito en llamadas a funciones (transferencias, reservas, acciones)
    - Fuerte seguimiento de instrucciones
    - Costo asequible

    **Usar para:**
    - Soporte al cliente
    - Reserva de citas
    - Procesamiento de pedidos
    - La mayoría de escenarios conversacionales

    **Disponible en:** OpenAI, Azure OpenAI (alojado en la UE)
  </Accordion>

  <Accordion title="Para Tareas Complejas: GPT-4.1" icon="brain">
    Cuando necesita máxima inteligencia y razonamiento.

    **Por qué funciona:**
    - Mejor razonamiento de su clase y lógica de múltiples pasos
    - Maneja solución de problemas complejos
    - Comprensión superior del contexto

    **Compensaciones:**
    - Mayor latencia que GPT-4.1 Mini
    - Mayor costo por conversación

    **Usar para:**
    - Soporte técnico con diagnósticos complejos
    - Conversaciones de ventas de múltiples pasos
    - Tareas que requieren razonamiento profundo

    **Disponible en:** OpenAI, Azure OpenAI (alojado en la UE)
  </Accordion>

  <Accordion title="Rápido y Asequible: Claude Haiku 4.5" icon="bolt">
    El modelo más rápido de Anthropic con fuerte rendimiento.

    **Por qué funciona:**
    - Tiempos de respuesta inferiores a un segundo
    - Buen equilibrio de velocidad e inteligencia
    - IA Constitucional para respuestas más seguras
    - Menor costo que Sonnet

    **Usar para:**
    - Centros de llamadas de alto volumen
    - Aplicaciones críticas en velocidad
    - Despliegues conscientes del presupuesto

    **Disponible en:** Anthropic
  </Accordion>

  <Accordion title="Código Abierto Ultra-Rápido: Groq Llama 3.1 8B" icon="rocket">
    Opción más rápida disponible, impulsada por hardware personalizado de Groq.

    **Por qué funciona:**
    - Tiempos de respuesta inferiores a 500ms
    - Maneja cientos de tokens por segundo
    - Modelo de código abierto
    - Costo muy bajo

    **Compensaciones:**
    - Menos inteligente que GPT-4.1 o Claude
    - Picos ocasionales de latencia bajo carga
    - Mejor para conversaciones simples

    **Usar para:**
    - Llamadas simples de calificación
    - IVR y enrutamiento
    - Escenarios de alto volumen y baja complejidad

    **Disponible en:** Groq
  </Accordion>

  <Accordion title="Más Inteligencia de Groq: Llama 3.3 70B" icon="layer-group">
    Mejor razonamiento manteniendo la ventaja de velocidad de Groq.

    **Por qué funciona:**
    - Mejora en calidad respecto al modelo 8B
    - Aún rápido en la infraestructura de Groq
    - Buen punto medio

    **Usar para:**
    - Cuando la calidad de Llama 3.1 8B no es suficiente
    - Necesita velocidad pero más inteligencia

    **Disponible en:** Groq
  </Accordion>
</AccordionGroup>

<Tip>
**Guía de decisión rápida:**
- Comience con **GPT-4.1 Mini** → confiable, rápido, excelente para la mayoría de casos de uso
- ¿Necesita más razonamiento? → **GPT-4.1**
- ¿Necesita más rápido/económico? → **Claude Haiku 4.5**
- ¿Necesita lo más rápido? → **Groq Llama 3.1 8B** (pero menos inteligente)
</Tip>

---

## Interfaz de Selección de Modelo

### Catálogo de Proveedores

La interfaz de selección de modelo agrupa proveedores con metadatos útiles:

<CardGroup cols={2}>
  <Card title="Íconos de Proveedor" icon="building">
    Marca visual para OpenAI, Anthropic, Groq, Azure y más
  </Card>
  <Card title="Insignia Alojado en la UE" icon="location-dot">
    Indica modelos que procesan datos dentro de regiones de la UE
  </Card>
  <Card title="Recuento de Modelos" icon="list-ol">
    Muestra cuántos modelos están disponibles de cada proveedor
  </Card>
  <Card title="Selección Activa" icon="check">
    Resalta su modelo seleccionado actualmente
  </Card>
</CardGroup>

### Filtrado y Búsqueda

Haga clic en un proveedor para filtrar la tabla de modelos solo a ese proveedor. Use el cuadro de búsqueda para encontrar rápidamente modelos específicos por nombre o capacidad.

---

## Detalles del Proveedor de Modelo

### OpenAI

Los modelos de OpenAI ofrecen el mejor equilibrio de confiabilidad y llamadas a funciones para agentes de voz.

**GPT-4.1 Mini** ⭐ **Recomendado**
- **Rendimiento en el mundo real:** ~700-800ms tiempo de respuesta, 70%+ tasa de éxito en llamadas a funciones
- **Mejor para:** Agentes de voz en producción - soporte, reservas, ventas
- **Por qué funciona:** Confiabilidad probada, excelente uso de herramientas, buena latencia

**GPT-4.1**
- **Rendimiento en el mundo real:** Mayor latencia que Mini pero razonamiento superior
- **Mejor para:** Conversaciones complejas de múltiples pasos, soporte técnico
- **Compensación:** Mayor costo y latencia por más inteligencia

**Serie GPT-5** (Mini, Nano)
- **Estado:** Modelos de próxima generación con razonamiento avanzado
- **Consideraciones:** GPT-5 tiene mayor latencia (~1s+); GPT-5 Mini ofrece mejor equilibrio
- **Mejor para:** Tareas donde la inteligencia importa más que la velocidad

**Modelos heredados** (GPT-4o, GPT-4o Mini)
- **Estado:** Aún funcionales pero considere la serie GPT-4.1/5 para nuevos agentes

### Azure OpenAI (Alojado en la UE)

Los mismos modelos de OpenAI alojados en la UE (región Suecia Central).

**Por qué elegir Azure OpenAI:**
- **Alojamiento en la UE:** Datos procesados dentro de la UE
- **Características empresariales:** Seguridad de Azure, cumplimiento, SLAs
- **Mismos modelos:** GPT-4.1, GPT-4.1 Mini, GPT-5 Mini/Nano

### Anthropic

Los modelos Claude destacan en seguridad, seguimiento de instrucciones y razonamiento complejo.

**Claude Haiku 4.5** ⭐ **Recomendado**
- **Rendimiento en el mundo real:** Respuestas inferiores a un segundo, excelente relación velocidad-inteligencia
- **Mejor para:** Despliegues críticos en velocidad, casos de uso de alto volumen
- **Por qué funciona:** Rápido, asequible, fuerte seguridad de IA Constitucional

**Claude Sonnet 4.5**
- **Rendimiento en el mundo real:** Excelente para flujos de trabajo de agentes complejos y uso de herramientas
- **Mejor para:** Razonamiento de múltiples pasos, procedimientos complejos, tareas de codificación
- **Consideraciones:** Puede tener picos de latencia bajo carga intensa; monitoree tiempos de espera en producción
- **Pensamiento extendido:** Soporta cadenas de razonamiento más largas para problemas complejos

<Note>
Los modelos Claude son **más conversacionales y ricos** en sus respuestas comparados con los modelos de OpenAI. Naturalmente proporcionan respuestas más completas y matizadas. Esto los hace excelentes para interacciones atractivas con clientes, pero ocasionalmente pueden disculparse en exceso. Pruebe con su caso de uso específico para ver si el estilo conversacional se ajusta a sus necesidades.
</Note>

### Groq (Latencia Ultra-Baja)

Modelos de código abierto en hardware personalizado para máxima velocidad.

**Llama 3.1 8B Instant** ⭐ **Más Rápido**
- **Rendimiento en el mundo real:** Tiempos de respuesta inferiores a 500ms, cientos de tokens/segundo
- **Mejor para:** Calificación simple, IVR, enrutamiento, escenarios de alto volumen
- **Compensación:** Menos inteligente que GPT-4.1 o Claude
- **Cuidado con:** Picos ocasionales de latencia bajo carga intensa

**Llama 3.3 70B Versatile**
- **Rendimiento en el mundo real:** Mejor razonamiento que 8B manteniendo la velocidad de Groq
- **Mejor para:** Cuando necesita más inteligencia que 8B pero quiere la ventaja de velocidad de Groq

**Serie GPT-OSS** (20B, 120B)
- **Rendimiento en el mundo real:** El modelo 20B es súper rápido en hardware Groq, similar a las velocidades de Llama
- **Estado:** Modelos de pesos abiertos de OpenAI con soporte para uso de herramientas
- **Mejor para:** Alternativa rápida de código abierto con llamadas a funciones

<Tip>
**Groq es perfecto para:** eliminar cuellos de botella de LLM cuando menos de 800ms es crítico y las tareas son directas (calificación, enrutamiento, recopilación de datos).
</Tip>

---

## Parámetros del Modelo

Haga clic en **Parámetros del Modelo** para acceder a opciones de configuración avanzadas que controlan cómo se comporta el modelo.

### Temperatura

Controla la aleatoriedad en las respuestas (rango: 0.0 a 2.0)

- **0.0 (Recomendado):** Respuestas deterministas y consistentes
  - Usar para: La mayoría de agentes de voz, llamadas a herramientas, ejecución de acciones
  - Maximiza la confiabilidad para transferencias, reservas y llamadas API
  - Asegura comportamiento consistente y respuestas predecibles

- **0.1 - 0.3:** Ligeramente variado pero aún muy consistente
  - Usar para: Agentes que necesitan ligera variación natural
  - Aún confiable para llamadas a herramientas

- **0.4 - 0.7:** Más creativo y variado
  - Usar para: Agentes impulsados por personalidad donde la creatividad importa más que la consistencia
  - La confiabilidad de llamadas a herramientas disminuye

- **0.8+:** Altamente creativo, impredecible
  - Evitar para agentes de voz en producción
  - Las llamadas a herramientas se vuelven no confiables

<Note>
**Recomendación predeterminada:** Use 0.0 a menos que su agente necesite más creatividad similar a la humana. La temperatura por encima de 0 reduce la confiabilidad de las llamadas a herramientas (transferencias, reservas, acciones).
</Note>

---

## Elegir el Modelo Correcto

### Marco de Decisión

Use este marco para seleccionar su modelo:

<AccordionGroup>
  <Accordion title="1. Comience con el Predeterminado Correcto" icon="star" defaultOpen>
    **Para la mayoría de casos de uso, comience aquí:**
    - **GPT-4.1 Mini** → Mejor equilibrio de velocidad, confiabilidad y costo
    - **Claude Haiku 4.5** → Cuando necesita respuestas más rápidas o menor costo

    **Solo actualice si necesita más inteligencia:**
    - **GPT-4.1** → Razonamiento complejo de múltiples pasos requerido
    - **Claude Sonnet 4.5** → Máxima calidad conversacional

    **Vaya más rápido/económico solo si es necesario:**
    - **Groq Llama 3.1 8B** → Velocidad inferior a 500ms es crítica
  </Accordion>

  <Accordion title="2. Ajustar a Su Caso de Uso" icon="brain">
    **Enrutamiento Simple / FAQ:**
    - Groq Llama 3.1 8B (más rápido)
    - Llama 3.3 70B (más inteligente)

    **Soporte al Cliente Estándar (Más Común):**
    - **GPT-4.1 Mini** ⭐ (recomendado - mejor equilibrio)
    - Claude Haiku 4.5 (más rápido, más conversacional)

    **Razonamiento Complejo / Soporte Técnico:**
    - GPT-4.1 (cuando Mini no es suficiente)
    - Claude Sonnet 4.5 (máxima calidad)

    **Crítico en Personalidad / Sensible a Marca:**
    - Claude Sonnet 4.5 (más rico, más conversacional)
    - GPT-4.1 (cuando necesita razonamiento + personalidad)
  </Accordion>

  <Accordion title="3. Alojamiento en la UE" icon="shield">
    **¿Necesita alojamiento compatible con GDPR en la UE?**
    - **Azure OpenAI** es el único proveedor con alojamiento en la UE
    - Todos los modelos GPT-4.1, GPT-4.1 Mini y GPT-5 disponibles
  </Accordion>
</AccordionGroup>

### Combinaciones Comunes de Modelos

Muchos clientes usan diferentes modelos para diferentes agentes:

```text wrap
Soporte Estándar → GPT-4.1 Mini (mejor predeterminado para la mayoría de agentes)
Enrutamiento de Alto Volumen → Groq Llama 3.1 8B (crítico en velocidad, tareas simples)
Reserva de Citas → GPT-4.1 Mini o Claude Haiku 4.5 (llamadas a herramientas confiables)
Solución de Problemas Compleja → GPT-4.1 (cuando necesita más razonamiento)
Crítico en Marca/Personalidad → Claude Sonnet 4.5 (conversaciones más ricas)
```

---

## Probar el Rendimiento del Modelo

### Pruebas A/B de Modelos

Para comparar modelos científicamente:

1. **Duplique su agente** en el panel de control
2. **Cambie solo el modelo** en una versión
3. **Mantenga todas las demás configuraciones idénticas** (instrucciones, voz, acciones)
4. **Ejecute escenarios de prueba idénticos** en ambos
5. **Compare:**
   - Calidad y precisión de la respuesta
   - Latencia y velocidad
   - Naturalidad de la conversación
   - Confiabilidad del activador de acción

### Criterios de Evaluación

Califique cada modelo en:

| Criterio | Qué Buscar |
|----------|------------|
| **Precisión** | ¿Comprende las solicitudes correctamente? |
| **Adherencia a Instrucciones** | ¿Sigue las reglas de su prompt del sistema? |
| **Latencia** | ¿Qué tan rápido responde? |
| **Retención de Contexto** | ¿Recuerda la conversación anterior? |
| **Sincronización de Acciones** | ¿Activa acciones en los momentos correctos? |
| **Manejo de Errores** | ¿Cómo maneja las solicitudes poco claras? |

---

## Mejores Prácticas

<AccordionGroup>
  <Accordion title="Comience con GPT-4.1 Mini" icon="rocket">
    Para la mayoría de agentes de voz, comience con:
    - **Modelo:** GPT-4.1 Mini
    - **Temperatura:** 0.0 (o 0.7 para más personalidad)

    Solo cambie si las pruebas muestran que necesita más inteligencia o velocidad más rápida.
  </Accordion>

  <Accordion title="No Gaste Demasiado en Inteligencia" icon="scale-balanced">
    **Comience pequeño, actualice solo si es necesario:**
    - La mayoría de casos de uso funcionan muy bien con GPT-4.1 Mini
    - Solo actualice a GPT-4.1 o Claude Sonnet 4.5 si Mini no puede manejar su complejidad
    - Use Groq para enrutamiento/FAQ simple donde la velocidad importa más que la inteligencia

    Ajuste la capacidad al requisito—no pague por inteligencia que no necesita.
  </Accordion>

  <Accordion title="Monitoree el Rendimiento en el Mundo Real" icon="chart-line">
    Use analíticas para rastrear:
    - Tiempo promedio de respuesta
    - Tasas de éxito de acciones
    - Tasas de transferencia (transferencias altas pueden indicar problemas de razonamiento)
    - Puntuaciones de satisfacción del cliente

    Cambie de modelo si las métricas se degradan.
  </Accordion>

  <Accordion title="Considere el Despliegue Regional" icon="globe">
    Si atiende clientes globales:
    - Use modelos alojados en la UE para llamantes europeos (GDPR)
    - Considere despliegues regionales de Azure para cumplimiento empresarial
    - Factor de latencia desde la región de alojamiento del modelo hasta los clientes
  </Accordion>

  <Accordion title="Documente Cambios de Modelo" icon="file-pen">
    Al cambiar modelos en producción:
    - Anote la fecha y la razón en la descripción del agente
    - Monitoree métricas durante 24-48 horas después
    - Mantenga documentado el ID del modelo anterior para reversión
    - Pruebe exhaustivamente antes de cambiar agentes de alto volumen
  </Accordion>
</AccordionGroup>

---

## Solución de Problemas del Modelo

### Las Respuestas del Agente Son Demasiado Prolijas

**Soluciones:**
- Agregue a las instrucciones: "Mantenga cada respuesta bajo 25 segundos"
- Use temperatura 0.0 para respuestas más enfocadas y concisas
- Considere modelo más rápido que fomente la brevedad

### El Agente Malinterpreta las Solicitudes

**Soluciones:**
- Cambie a modelo de mayor capacidad (GPT-4.1, Claude Sonnet 4.5)
- Mejore las instrucciones con ejemplos más específicos
- Agregue refuerzo de palabras clave en configuraciones del transcriptor
- Revise primero la precisión de la transcripción (puede ser problema STT, no LLM)

### El Agente No Sigue las Instrucciones

**Soluciones:**
- Los modelos Claude típicamente mejores en adherencia a instrucciones
- Simplifique y clarifique las instrucciones
- Use listas con viñetas en lugar de párrafos
- Agregue ejemplos explícitos de comportamiento correcto
- Use temperatura 0.0 para máxima consistencia

### Alta Latencia / Respuestas Lentas

**Soluciones:**
- Cambie a modelo más rápido (Groq Llama 3.1 8B, Claude Haiku 4.5)
- Verifique si el problema es latencia del modelo o de red (pruebe con diferentes proveedores)

### El Agente Repite las Mismas Frases

**Soluciones:**
- Agregue instrucción: "Varíe su redacción; evite expresiones repetitivas"
- Considere modelo diferente (algunos tienen mejor diversidad)
- Revise si las instrucciones causan inadvertidamente repetición

---

## Actualizaciones y Versiones del Modelo

### Actualizaciones del Modelo del Proveedor

Los proveedores de modelos actualizan regularmente sus ofertas:
- **Actualizaciones menores** a menudo mejoran el rendimiento sin cambios que rompan
- **Cambios de versión principales** (ej., GPT-4 → GPT-5) pueden requerir pruebas
- itellicoAI notifica a los clientes antes de actualizaciones automáticas de versión

### Controlar Versiones del Modelo

Algunos proveedores le permiten fijar versiones específicas:
- **Última:** Siempre use la versión más nueva (predeterminado, recomendado)
- **Fija:** Permanezca en versión específica (use si ha optimizado mucho para ese modelo)

### Política de Depreciación

Cuando los proveedores deprecian modelos:
1. itellicoAI notifica a los clientes afectados con anticipación
2. Se proporciona ruta de migración recomendada
3. Los agentes se mueven automáticamente al modelo sucesor si no se toma acción
4. Asistencia de migración disponible desde soporte

---

## Próximos Pasos

<CardGroup cols={2}>
  <Card title="Seleccionar Voz" icon="microphone" href="/es/build/voice-speech/select-voice">
    Configure cómo suena su agente con la selección de voz
  </Card>
  <Card title="Configuración del Transcriptor" icon="ear" href="/es/build/voice-speech/transcriber">
    Elija modelos de transcripción para escuchar a los clientes
  </Card>
  <Card title="Configuraciones de Voz" icon="sliders" href="/es/build/voice-speech/voice-settings">
    Ajuste la velocidad, tono y timbre para su voz
  </Card>
  <Card title="Pruebe Su Agente" icon="vial" href="/es/test/web-simulator">
    Pruebe el rendimiento del modelo con llamadas web
  </Card>
</CardGroup>
