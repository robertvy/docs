---
title: "Escolher Modelo de IA"
description: "Selecione e configure o modelo de linguagem que alimenta o raciocínio do seu agente"
icon: "brain"
"keywords": "seleção de modelo de IA, modelos de linguagem, GPT-4, Claude, seleção de LLM, inteligência de IA, configuração de modelo, cérebro do agente"
"og:description": "Selecione e configure o modelo de linguagem que alimenta o raciocínio do seu agente de IA, desde GPT-4 até Claude e outros."
---

## Visão Geral

O modelo de IA (LLM) é o cérebro do seu agente de voz. Ele processa o que os clientes dizem, entende suas intenções, raciocina sobre a melhor resposta e decide quando executar ações. Escolher o modelo certo significa equilibrar desempenho, latência, custo e requisitos de conformidade.

<Note>
A seleção do modelo acontece em **Modelos > Modelo** na configuração do seu agente. As alterações são aplicadas imediatamente—não é necessária uma etapa de publicação separada.
</Note>

## Entendendo Modelos de Linguagem

Modelos de linguagem são treinados em grandes quantidades de texto para entender e gerar linguagem humana. Em agentes de voz, o LLM interpreta solicitações de clientes, raciocina sobre a melhor resposta com base em suas instruções e base de conhecimento, decide quando usar ações como transferências ou agendamentos, gera respostas de conversação naturais e mantém o contexto durante toda a conversa.

Diferentes modelos se destacam em diferentes tarefas. Alguns priorizam velocidade, outros precisão, e alguns oferecem o melhor equilíbrio para IA conversacional.

---

## Modelos Recomendados

Com base no desempenho do mundo real de milhares de agentes de voz, aqui estão os modelos comprovados para diferentes casos de uso:

<AccordionGroup>
  <Accordion title="Melhor para a Maioria dos Casos: GPT-4.1 Mini" icon="star" defaultOpen>
    **Nossa principal recomendação** para agentes de voz em produção.

    **Por que funciona:**
    - Excelente latência (~700-800ms de tempo de resposta)
    - 70%+ de taxa de sucesso em chamadas de função (transferências, agendamentos, ações)
    - Forte adesão às instruções
    - Custo acessível

    **Use para:**
    - Suporte ao cliente
    - Agendamento de consultas
    - Processamento de pedidos
    - A maioria dos cenários de conversação

    **Disponível em:** OpenAI, Azure OpenAI (hospedado na UE)
  </Accordion>

  <Accordion title="Para Tarefas Complexas: GPT-4.1" icon="brain">
    Quando você precisa de máxima inteligência e raciocínio.

    **Por que funciona:**
    - Raciocínio de primeira classe e lógica de múltiplas etapas
    - Lida com solução de problemas complexos
    - Compreensão de contexto superior

    **Compensações:**
    - Latência maior que GPT-4.1 Mini
    - Custo maior por conversa

    **Use para:**
    - Suporte técnico com diagnósticos complexos
    - Conversas de vendas com múltiplas etapas
    - Tarefas que exigem raciocínio profundo

    **Disponível em:** OpenAI, Azure OpenAI (hospedado na UE)
  </Accordion>

  <Accordion title="Rápido e Acessível: Claude Haiku 4.5" icon="bolt">
    O modelo mais rápido da Anthropic com forte desempenho.

    **Por que funciona:**
    - Tempos de resposta abaixo de um segundo
    - Bom equilíbrio entre velocidade e inteligência
    - IA Constitucional para respostas mais seguras
    - Custo menor que Sonnet

    **Use para:**
    - Centrais de atendimento de alto volume
    - Aplicações críticas em termos de velocidade
    - Implantações com orçamento limitado

    **Disponível em:** Anthropic
  </Accordion>

  <Accordion title="Código Aberto Ultra-Rápido: Groq Llama 3.1 8B" icon="rocket">
    Opção mais rápida disponível, alimentada pelo hardware personalizado da Groq.

    **Por que funciona:**
    - Tempos de resposta abaixo de 500ms
    - Lida com centenas de tokens por segundo
    - Modelo de código aberto
    - Custo muito baixo

    **Compensações:**
    - Menos inteligente que GPT-4.1 ou Claude
    - Picos ocasionais de latência sob carga
    - Melhor para conversas mais simples

    **Use para:**
    - Chamadas simples de qualificação
    - IVR e roteamento
    - Cenários de alto volume e baixa complexidade

    **Disponível em:** Groq
  </Accordion>

  <Accordion title="Mais Inteligência da Groq: Llama 3.3 70B" icon="layer-group">
    Melhor raciocínio mantendo a vantagem de velocidade da Groq.

    **Por que funciona:**
    - Aumento de qualidade em relação ao modelo 8B
    - Ainda rápido na infraestrutura Groq
    - Bom meio-termo

    **Use para:**
    - Quando a qualidade do Llama 3.1 8B não é suficiente
    - Precisa de velocidade mas com mais inteligência

    **Disponível em:** Groq
  </Accordion>
</AccordionGroup>

<Tip>
**Guia de decisão rápida:**
- Comece com **GPT-4.1 Mini** → confiável, rápido, ótimo para a maioria dos casos
- Precisa de mais raciocínio? → **GPT-4.1**
- Precisa de mais rápido/barato? → **Claude Haiku 4.5**
- Precisa do mais rápido? → **Groq Llama 3.1 8B** (mas menos inteligente)
</Tip>

---

## Interface de Seleção de Modelo

### Catálogo de Provedores

A interface de seleção de modelo agrupa provedores com metadados úteis:

<CardGroup cols={2}>
  <Card title="Ícones de Provedores" icon="building">
    Marca visual para OpenAI, Anthropic, Groq, Azure e outros
  </Card>
  <Card title="Badge Hospedado na UE" icon="location-dot">
    Indica modelos que processam dados dentro de regiões da UE
  </Card>
  <Card title="Contagem de Modelos" icon="list-ol">
    Mostra quantos modelos estão disponíveis de cada provedor
  </Card>
  <Card title="Seleção Ativa" icon="check">
    Destaca seu modelo atualmente selecionado
  </Card>
</CardGroup>

### Filtragem e Pesquisa

Clique em um provedor para filtrar a tabela de modelos apenas para esse fornecedor. Use a caixa de pesquisa para encontrar rapidamente modelos específicos por nome ou capacidade.

---

## Detalhes dos Provedores de Modelos

### OpenAI

Os modelos OpenAI oferecem o melhor equilíbrio entre confiabilidade e chamadas de função para agentes de voz.

**GPT-4.1 Mini** ⭐ **Recomendado**
- **Desempenho no mundo real:** ~700-800ms de tempo de resposta, 70%+ de taxa de sucesso em chamadas de função
- **Melhor para:** Agentes de voz em produção - suporte, agendamento, vendas
- **Por que funciona:** Confiabilidade comprovada, excelente uso de ferramentas, boa latência

**GPT-4.1**
- **Desempenho no mundo real:** Latência maior que Mini mas raciocínio superior
- **Melhor para:** Conversas complexas de múltiplas etapas, suporte técnico
- **Compensação:** Custo e latência maiores para mais inteligência

**Série GPT-5** (Mini, Nano)
- **Status:** Modelos de próxima geração com raciocínio avançado
- **Considerações:** GPT-5 tem latência maior (~1s+); GPT-5 Mini oferece melhor equilíbrio
- **Melhor para:** Tarefas onde inteligência importa mais que velocidade

**Modelos legados** (GPT-4o, GPT-4o Mini)
- **Status:** Ainda funcionais, mas considere a série GPT-4.1/5 para novos agentes

### Azure OpenAI (Hospedado na UE)

Os mesmos modelos OpenAI hospedados na UE (região Central da Suécia).

**Por que escolher Azure OpenAI:**
- **Hospedagem na UE:** Dados processados dentro da UE
- **Recursos empresariais:** Segurança Azure, conformidade, SLAs
- **Mesmos modelos:** GPT-4.1, GPT-4.1 Mini, GPT-5 Mini/Nano

### Anthropic

Os modelos Claude se destacam em segurança, adesão a instruções e raciocínio complexo.

**Claude Haiku 4.5** ⭐ **Recomendado**
- **Desempenho no mundo real:** Respostas abaixo de um segundo, excelente relação velocidade-inteligência
- **Melhor para:** Implantações críticas em termos de velocidade, casos de uso de alto volume
- **Por que funciona:** Rápido, acessível, forte segurança de IA Constitucional

**Claude Sonnet 4.5**
- **Desempenho no mundo real:** Excelente para fluxos de trabalho complexos de agentes e uso de ferramentas
- **Melhor para:** Raciocínio de múltiplas etapas, procedimentos complexos, tarefas de codificação
- **Considerações:** Pode ter picos de latência sob carga pesada; monitore timeouts em produção
- **Pensamento estendido:** Suporta cadeias de raciocínio mais longas para problemas complexos

<Note>
Os modelos Claude são **mais conversacionais e ricos** em suas respostas comparados aos modelos OpenAI. Eles naturalmente fornecem respostas mais completas e nuançadas. Isso os torna excelentes para interações envolventes com clientes, mas eles podem ocasionalmente se desculpar demais. Teste com seu caso de uso específico para ver se o estilo conversacional atende às suas necessidades.
</Note>

### Groq (Latência Ultra-Baixa)

Modelos de código aberto em hardware personalizado para velocidade máxima.

**Llama 3.1 8B Instant** ⭐ **Mais Rápido**
- **Desempenho no mundo real:** Tempos de resposta abaixo de 500ms, centenas de tokens/segundo
- **Melhor para:** Qualificação simples, IVR, roteamento, cenários de alto volume
- **Compensação:** Menos inteligente que GPT-4.1 ou Claude
- **Atenção para:** Picos ocasionais de latência sob carga pesada

**Llama 3.3 70B Versatile**
- **Desempenho no mundo real:** Melhor raciocínio que 8B mantendo velocidade da Groq
- **Melhor para:** Quando você precisa de mais inteligência que 8B mas quer a vantagem de velocidade da Groq

**Série GPT-OSS** (20B, 120B)
- **Desempenho no mundo real:** Modelo 20B é super rápido no hardware Groq, similar às velocidades do Llama
- **Status:** Modelos OpenAI de peso aberto com suporte a uso de ferramentas
- **Melhor para:** Alternativa de código aberto rápida com chamadas de função

<Tip>
**Groq é perfeito para:** remover gargalos de LLM quando abaixo de 800ms é crítico e as tarefas são diretas (qualificação, roteamento, coleta de dados).
</Tip>

---

## Parâmetros do Modelo

Clique em **Parâmetros do Modelo** para acessar opções de configuração avançadas que controlam como o modelo se comporta.

### Temperatura

Controla a aleatoriedade nas respostas (faixa: 0.0 a 2.0)

- **0.0 (Recomendado):** Respostas determinísticas e consistentes
  - Use para: A maioria dos agentes de voz, chamadas de ferramentas, execução de ações
  - Maximiza a confiabilidade para transferências, agendamentos e chamadas de API
  - Garante comportamento consistente e respostas previsíveis

- **0.1 - 0.3:** Ligeiramente variado mas ainda altamente consistente
  - Use para: Agentes que precisam de leve variação natural
  - Ainda confiável para chamadas de ferramentas

- **0.4 - 0.7:** Mais criativo e variado
  - Use para: Agentes orientados à personalidade onde criatividade importa mais que consistência
  - Confiabilidade das chamadas de ferramentas diminui

- **0.8+:** Altamente criativo, imprevisível
  - Evite para agentes de voz em produção
  - Chamadas de ferramentas se tornam não confiáveis

<Note>
**Recomendação padrão:** Use 0.0 a menos que seu agente precise de mais criatividade humana. Temperatura acima de 0 reduz a confiabilidade das chamadas de ferramentas (transferências, agendamentos, ações).
</Note>

---

## Escolhendo o Modelo Certo

### Framework de Decisão

Use este framework para selecionar seu modelo:

<AccordionGroup>
  <Accordion title="1. Comece com o Padrão Correto" icon="star" defaultOpen>
    **Para a maioria dos casos de uso, comece aqui:**
    - **GPT-4.1 Mini** → Melhor equilíbrio entre velocidade, confiabilidade e custo
    - **Claude Haiku 4.5** → Quando você precisa de respostas mais rápidas ou menor custo

    **Só atualize se precisar de mais inteligência:**
    - **GPT-4.1** → Raciocínio complexo de múltiplas etapas necessário
    - **Claude Sonnet 4.5** → Qualidade conversacional máxima

    **Vá mais rápido/barato apenas se necessário:**
    - **Groq Llama 3.1 8B** → Velocidade abaixo de 500ms é crítica
  </Accordion>

  <Accordion title="2. Combine com Seu Caso de Uso" icon="brain">
    **Roteamento Simples / FAQ:**
    - Groq Llama 3.1 8B (mais rápido)
    - Llama 3.3 70B (mais inteligente)

    **Suporte ao Cliente Padrão (Mais Comum):**
    - **GPT-4.1 Mini** ⭐ (recomendado - melhor equilíbrio)
    - Claude Haiku 4.5 (mais rápido, mais conversacional)

    **Raciocínio Complexo / Suporte Técnico:**
    - GPT-4.1 (quando Mini não é suficiente)
    - Claude Sonnet 4.5 (qualidade máxima)

    **Crítico em Personalidade / Sensível à Marca:**
    - Claude Sonnet 4.5 (mais rico, mais conversacional)
    - GPT-4.1 (quando você precisa de raciocínio + personalidade)
  </Accordion>

  <Accordion title="3. Hospedagem na UE" icon="shield">
    **Precisa de hospedagem compatível com GDPR na UE?**
    - **Azure OpenAI** é o único provedor com hospedagem na UE
    - Todos os modelos GPT-4.1, GPT-4.1 Mini e GPT-5 disponíveis
  </Accordion>
</AccordionGroup>

### Combinações Comuns de Modelos

Muitos clientes usam diferentes modelos para diferentes agentes:

```text wrap
Suporte Padrão → GPT-4.1 Mini (melhor padrão para a maioria dos agentes)
Roteamento de Alto Volume → Groq Llama 3.1 8B (crítico em velocidade, tarefas simples)
Agendamento de Consultas → GPT-4.1 Mini ou Claude Haiku 4.5 (chamadas de ferramentas confiáveis)
Solução de Problemas Complexos → GPT-4.1 (quando você precisa de mais raciocínio)
Crítico em Marca/Personalidade → Claude Sonnet 4.5 (conversas mais ricas)
```

---

## Testando Desempenho do Modelo

### Teste A/B de Modelos

Para comparar modelos cientificamente:

1. **Duplique seu agente** no painel
2. **Altere apenas o modelo** em uma versão
3. **Mantenha todas as outras configurações idênticas** (instruções, voz, ações)
4. **Execute cenários de teste idênticos** em ambos
5. **Compare:**
   - Qualidade e precisão da resposta
   - Latência e velocidade
   - Naturalidade da conversa
   - Confiabilidade do acionamento de ações

### Critérios de Avaliação

Avalie cada modelo em:

| Critério | O Que Procurar |
|----------|----------------|
| **Precisão** | Ele entende solicitações corretamente? |
| **Adesão às Instruções** | Ele segue as regras do seu prompt de sistema? |
| **Latência** | Quão rápido ele responde? |
| **Retenção de Contexto** | Ele lembra da conversa anterior? |
| **Tempo de Ação** | Ele aciona ações nos momentos certos? |
| **Tratamento de Erros** | Como ele lida com solicitações pouco claras? |

---

## Melhores Práticas

<AccordionGroup>
  <Accordion title="Comece com GPT-4.1 Mini" icon="rocket">
    Para a maioria dos agentes de voz, comece com:
    - **Modelo:** GPT-4.1 Mini
    - **Temperatura:** 0.0 (ou 0.7 para mais personalidade)

    Só mude se os testes mostrarem que você precisa de mais inteligência ou velocidade mais rápida.
  </Accordion>

  <Accordion title="Não Gaste Demais em Inteligência" icon="scale-balanced">
    **Comece pequeno, atualize apenas se necessário:**
    - A maioria dos casos de uso funciona muito bem com GPT-4.1 Mini
    - Só atualize para GPT-4.1 ou Claude Sonnet 4.5 se Mini não conseguir lidar com sua complexidade
    - Use Groq para roteamento simples/FAQ onde velocidade importa mais que inteligência

    Combine capacidade com requisito—não pague por inteligência que você não precisa.
  </Accordion>

  <Accordion title="Monitore Desempenho no Mundo Real" icon="chart-line">
    Use análises para rastrear:
    - Tempo médio de resposta
    - Taxas de sucesso de ações
    - Taxas de transferência (transferências altas podem indicar problemas de raciocínio)
    - Pontuações de satisfação do cliente

    Mude de modelo se as métricas piorarem.
  </Accordion>

  <Accordion title="Considere Implantação Regional" icon="globe">
    Se atender clientes globais:
    - Use modelos hospedados na UE para chamadores europeus (GDPR)
    - Considere implantações regionais Azure para conformidade empresarial
    - Considere a latência da região de hospedagem do modelo até os clientes
  </Accordion>

  <Accordion title="Documente Mudanças de Modelo" icon="file-pen">
    Ao alterar modelos em produção:
    - Anote a data e motivo na descrição do agente
    - Monitore métricas por 24-48 horas depois
    - Mantenha o ID do modelo anterior documentado para reversão
    - Teste completamente antes de mudar agentes de alto volume
  </Accordion>
</AccordionGroup>

---

## Solução de Problemas do Modelo

### Respostas do Agente São Muito Verbosas

**Soluções:**
- Adicione às instruções: "Mantenha cada resposta abaixo de 25 segundos"
- Use temperatura 0.0 para respostas mais focadas e concisas
- Considere modelo mais rápido que encoraja brevidade

### Agente Não Entende Solicitações

**Soluções:**
- Mude para modelo de capacidade superior (GPT-4.1, Claude Sonnet 4.5)
- Melhore instruções com exemplos mais específicos
- Adicione aumento de palavras-chave nas configurações do transcritor
- Revise precisão da transcrição primeiro (pode ser problema de STT, não LLM)

### Agente Não Segue Instruções

**Soluções:**
- Modelos Claude tipicamente melhores em adesão a instruções
- Simplifique e esclareça instruções
- Use listas com marcadores em vez de parágrafos
- Adicione exemplos explícitos de comportamento correto
- Use temperatura 0.0 para máxima consistência

### Alta Latência / Respostas Lentas

**Soluções:**
- Mude para modelo mais rápido (Groq Llama 3.1 8B, Claude Haiku 4.5)
- Verifique se problema é latência do modelo ou da rede (teste com diferentes provedores)

### Agente Repete Mesmas Frases

**Soluções:**
- Adicione instrução: "Varie suas frases; evite expressões repetitivas"
- Considere modelo diferente (alguns têm melhor diversidade)
- Revise se instruções inadvertidamente causam repetição

---

## Atualizações e Versionamento de Modelos

### Atualizações de Modelos dos Provedores

Provedores de modelos atualizam regularmente suas ofertas:
- **Atualizações menores** geralmente melhoram desempenho sem mudanças disruptivas
- **Mudanças de versão principal** (ex: GPT-4 → GPT-5) podem requerer testes
- itellicoAI notifica clientes antes de atualizações automáticas de versão

### Controlando Versões de Modelos

Alguns provedores permitem fixar versões específicas:
- **Mais recente:** Sempre use versão mais nova (padrão, recomendado)
- **Fixado:** Permanecer em versão específica (use se você otimizou pesadamente para esse modelo)

### Política de Descontinuação

Quando provedores descontinuam modelos:
1. itellicoAI notifica clientes afetados com antecedência
2. Caminho de migração recomendado fornecido
3. Agentes automaticamente movidos para modelo sucessor se nenhuma ação for tomada
4. Assistência de migração disponível pelo suporte

---

## Próximos Passos

<CardGroup cols={2}>
  <Card title="Selecionar Voz" icon="microphone" href="/pt/build/voice-speech/select-voice">
    Configure como seu agente soa com seleção de voz
  </Card>
  <Card title="Configuração do Transcritor" icon="ear" href="/pt/build/voice-speech/transcriber">
    Escolha modelos de transcrição para ouvir clientes
  </Card>
  <Card title="Configurações de Voz" icon="sliders" href="/pt/build/voice-speech/voice-settings">
    Ajuste velocidade, tom e timbre para sua voz
  </Card>
  <Card title="Teste Seu Agente" icon="vial" href="/pt/test/web-simulator">
    Teste desempenho do modelo com chamadas web
  </Card>
</CardGroup>
